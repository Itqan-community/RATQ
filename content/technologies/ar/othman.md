# متصفح القرآن عثمان

## نظرة عامة

عثمان هو متصفح إلكتروني للقرآن يعرض النص القرآني بخط عثماني كما كُتب تحت إشراف عثمان بن عفان (رضي الله عنه)، صحابي النبي محمد (صلى الله عليه وسلم). يتميز التطبيق بقدرات بحث سريعة، والتمرير التلقائي، وإمكانية نسخ النص القرآني إلى الحافظة.

## جدول المحتويات

- [نظرة عامة](#نظرة-عامة)
- [جدول المحتويات](#جدول-المحتويات)
- [هيكل المشروع](#هيكل-المشروع)
- [بنية محرك البحث](#بنية-محرك-البحث)
- [مخطط قاعدة البيانات](#مخطط-قاعدة-البيانات)
- [خصائص الأداء](#خصائص-الأداء)
- [قرارات التصميم التقني](#قرارات-التصميم-التقني)
- [البناء والتثبيت](#البناء-والتثبيت)
- [الترخيص](#الترخيص)

## هيكل المشروع

يتكون المشروع من عدة مكونات رئيسية:

- **الوحدة الأساسية** (`othman/core.py`): يوفر وصول API إلى النص القرآني ووظائف البحث
- **واجهة GTK** (`othman/gtkUi.py`): واجهة المستخدم الرسومية المبنية بـ GTK3
- **قاعدة البيانات**: قواعد بيانات SQLite تخزن النص القرآني (`quran.db`) وفهرس البحث (`ix.db`)
- **ترميز الأعداد الصحيحة متغيرة الطول** (`othman/univaruints.py`): تسلسل مخصص لتخزين الفهرس بكفاءة

## بنية محرك البحث

### نظرة عامة

محرك البحث في عثمان مبني حول بنية فهرس مقلوب تمكن من مطابقة سريعة للكلمات الجزئية عبر 6,236 آية من القرآن. يعطي التنفيذ الأولوية لكل من السرعة وكفاءة التخزين من خلال تقنيات ترميز مخصصة.

### هيكل الفهرس

يتم تنفيذ فهرس البحث في فئة `searchIndexer` ويتكون من:

1. **قاموس المصطلحات**: يربط الكلمات العربية المعيارية بقوائم معرفات الآيات (Aya IDs)
2. **تخزين SQLite**: يحفظ الفهرس في `ix.db` بهيكل:
   ```sql
   CREATE TABLE ix (w TEXT PRIMARY KEY NOT NULL, i BLOB)
   ```
   - `w`: مصطلح البحث المعياري
   - `i`: قائمة مضغوطة من معرفات الآيات التي تحتوي على ذلك المصطلح

### توحيد النص

قبل الفهرسة أو البحث، يخضع جميع النص للتوحيد للتعامل مع اختلافات الخط العربي:

```python
normalize_tb = {
    65: 97, 66: 98, ...,  # A-Z to a-z
    1569: 1575,  # Alef variations → Alef
    1570: 1575,  # Alef with Hamza above
    1571: 1575,  # Alef with Hamza below
    1572: 1575,  # Waw with Hamza
    1573: 1575,  # Alef with Hamza below
    1574: 1575,  # Yeh with Hamza
    1577: 1607,  # Teh Marbuta → Heh
    1609: 1575,  # Alef Maksura → Alef
    1611: None,  # Fathatan (removed)
    1612: None,  # Dammatan (removed)
    # ... other diacritics removed
}
```

هذا التوحيد:
- يحول الأحرف الكبيرة إلى صغيرة للأحرف اللاتينية
- يوحد اختلافات الألف (أ، إ، آ، ا)
- يزيل جميع علامات التشكيل العربية (التشكيل)
- يوحد التاء المربوطة إلى الهاء
- يحول الألف المقصورة إلى ألف

### توليد الفهرس

يتم بناء الفهرس أثناء التثبيت بواسطة سكريبت `gen-index.py`:

```python
q = othmanCore(False)
ix = searchIndexer(True)
wc = 0
for n,(o,i) in enumerate(q.getAyatIter(1, 6236)):
    for w in i.split():
        ix.addWord(w, n+1)
        wc += 1
ix.save()
```

**العملية:**
1. التكرار عبر جميع 6,236 آية
2. تقسيم كل آية إلى كلمات
3. توحيد وإضافة كل كلمة إلى الفهرس مع معرف الآية
4. حفظ الفهرس المضغوط على القرص

**إحصائيات الفهرس:**
- إجمالي الكلمات المفهرسة: ~77,000+
- المصطلحات الفريدة: ~18,000+
- أقصى طول للمصطلح: متغير، يتم تتبعه أثناء الفهرسة
- إجمالي حجم الفهرس: مضغوط باستخدام ترميز متغير الطول

### الضغط: ترميز الأعداد الصحيحة متغيرة الطول

يستخدم الفهرس مخطط ترميز مخصص متغير الطول (`univaruints.py`) لتقليل التخزين:

#### استراتيجية الترميز

بدلاً من تخزين كل معرف آية كعدد صحيح ثابت 64 بت (8 بايت)، يستخدم الترميز 1-8 بايت اعتماداً على حجم القيمة:

| نطاق القيمة | البايتات المستخدمة | نمط البايت الأول |
|-------------|------------|-------------------|
| 0-127 | 1 | `0xxxxxxx` |
| 128-16,511 | 2 | `10xxxxxx` |
| 16,512-2,113,663 | 3 | `110xxxxx` |
| ... | ... | ... |
| حتى 2^64 | 8 | `11111111` |

#### الترميز التدريجي

بما أن معرفات الآيات مخزنة بترتيب مرتب، يستخدم الفهرس **ترميز دلتا** (ترميز تدريجي):

```python
def incremental_encode_list(a, unique=1, last=0):
    last -= unique
    for i in a:
        if i < last + unique:
            raise ValueError
        yield i - last - unique  # Store the difference
        last = i
```

**مثال:**
- المعرفات الأصلية: `[5, 12, 45, 89, 234]`
- التدريجية: `[5, 7, 33, 44, 145]`
- الفوائد: الفروق الأصغر = حاجة لبايتات أقل

#### كفاءة التخزين

لمصطلح يظهر في 100 آية متتالية:
- **بدون ضغط**: 100 × 8 بايت = 800 بايت
- **مع ترميز متغير الطول**: ~100-200 بايت
- **نسبة الضغط**: تقليل 4-8x

### عمليات البحث

#### البحث الدقيق للكلمة

```python
def find(self, words):
    if not words:
        return None
    w = self.normalize(words[0])
    W, x = self.get(w)
    if not x:
        return None
    for w in words[1:]:
        W, y = self.get(self.normalize(w))
        if not y:
            return None
        x &= y  # Set intersection
    return x.toAyaIdList()
```

**الخوارزمية:**
1. توحيد كلمة البحث الأولى
2. استرجاع مجموعة معرفات الآيات التي تحتوي على تلك الكلمة
3. لكل كلمة إضافية:
   - استرجاع مجموعة معرفات الآيات الخاصة بها
   - تقاطع مع المجموعة المتراكمة
4. إرجاع قائمة مرتبة من معرفات الآيات المطابقة

**التعقيد:** O(n × m) حيث n = عدد مصطلحات البحث، m = متوسط حجم المجموعة

#### البحث الجزئي للكلمة (مطابقة السلسلة الفرعية)

```python
def findPartial(self, words):
    if not words:
        return None
    w = self.normalize(words[0])
    x = reduce(lambda a,b: a|b, self.getPartial(w), searchIndexerItem())
    for W in words[1:]:
        w = self.normalize(W)
        y = reduce(lambda a,b: a|b, self.getPartial(w), searchIndexerItem())
        x &= y
    return x.toAyaIdList()
```

**الخوارزمية:**
1. استخدام مطابقة نمط SQL `LIKE`: `WHERE w LIKE '%searchterm%'`
2. اتحاد جميع مجموعات المصطلحات المطابقة للكلمة الأولى
3. التكرار لكل كلمة إضافية وتقاطع النتائج
4. إرجاع قائمة مرتبة من معرفات الآيات المطابقة

**مثال:**
- البحث: "رحم" (رحمة)
- المطابقات: "الرحمن", "الرحيم", "رحمة", "يرحم"، إلخ.
- إرجاع جميع الآيات التي تحتوي على أي كلمة بها "رحم"

### عمليات المجموعات

تمتد فئة `searchIndexerItem` من `set` في Python لمعالجة فعالة لمعرفات الآيات:

```python
class searchIndexerItem(set):
    def __or__(self, y):
        return self.union(y)  # Union for partial match
    
    def __and__(self, y):
        return self.intersection(y)  # Intersection for multi-word
    
    def toAyaIdList(self):
        l = list(self)
        l.sort()
        return l
```

**عمليات المجموعات:**
- **الاتحاد (`|`)**: دمج النتائج من عدة مطابقات جزئية
- **التقاطع (`&`)**: العثور على الآيات التي تحتوي على جميع مصطلحات البحث
- **الترتيب**: عرض النتائج بترتيب قرآني

### أمان الخيوط

يدعم محرك البحث الوصول متعدد الخيوط من خلال تجميع الاتصالات:

```python
def _getConnection(self):
    n = threading.current_thread().name
    if n in self._cn.keys():
        r = self._cn[n]
    else:
        r = sqlite3.connect(self.db_fn)
        self._cn[n] = r
    return r
```

كل خيط يحافظ على اتصال SQLite الخاص به، مما يمنع التعارضات أثناء عمليات البحث المتزامنة.

### تكامل واجهة المستخدم

يتم عرض وظيفة البحث من خلال نافذة بحث مخصصة (فئة `searchWindow`):

**الميزات:**
1. **البحث المباشر**: اضغط Enter لتنفيذ البحث
2. **عرض النتائج**: يعرض اسم السورة ورقمها ورقم الآية
3. **التنقل**: انقر على أي نتيجة للانتقال إلى تلك الآية
4. **الاستمرارية**: يتذكر آخر بحث للتنقل السريع

**تدفق البحث:**
1. المستخدم يدخل النص في صندوق البحث
2. يتم تقسيم النص إلى كلمات وتوحيده
3. `findPartial()` ينفذ بحث السلسلة الفرعية
4. النتائج تملأ عرض الشجرة بمعلومات السورة/الآية
5. النقر على نتيجة يمرر العرض الرئيسي إلى تلك الآية

## مخطط قاعدة البيانات

### جدول القرآن
```sql
SELECT othmani, imlai FROM Quran WHERE id>=? ORDER BY id LIMIT ?
```

- **othmani**: النص بخط عثماني (مع الإملاء القرآني)
- **imlai**: النص بالإملاء العربي الحديث
- **id**: معرف الآية (1-6236)

### جدول SuraInfo
```sql
SELECT rowid, sura_name, other_names, makki, starting_row, comment 
FROM SuraInfo ORDER BY rowid
```

يخزن البيانات الوصفية لجميع 114 سورة بما في ذلك الأسماء، تصنيف مكي/مدني، ومعرفات الآيات البادئة.

## خصائص الأداء

### توليد الفهرس
- **الوقت**: ~1-3 ثوانٍ للقرآن الكامل
- **الذاكرة**: ذروة ~50-100 ميجابايت أثناء الفهرسة
- **القرص**: ~500 كيلوبايت للفهرس المضغوط

### أداء البحث
- **المطابقة الدقيقة**: < 10ms لكلمة واحدة
- **متعدد الكلمات الدقيق**: < 50ms لـ 2-3 كلمات
- **المطابقة الجزئية**: < 100ms لسلسلة فرعية واحدة
- **متعدد الكلمات الجزئي**: < 200ms لـ 2-3 سلاسل فرعية

### استخدام الذاكرة
- **وقت التشغيل**: ~20-30 ميجابايت للفهرس في الذاكرة
- **لكل بحث**: < 1 ميجابايت تخصيص إضافي
- **مجموعات النتائج**: ~100 بايت لكل آية مطابقة

## قرارات التصميم التقني

### لماذا الترميز المخصص؟

1. **خصائص النص العربي**: القرآن له أنماط تكرار كلمات محددة
2. **المعرفات المتسلسلة**: معرفات الآيات مرتبة طبيعياً، مما يمكن من ترميز دلتا
3. **تحسين التخزين**: يقلل حجم الفهرس بمقدار 4-8x مقابل الأعداد الصحيحة بعرض ثابت
4. **فك التشفير السريع**: فك تشفير بمرور واحد مع حد أدنى من الحمل

### لماذا SQLite؟

1. **صفر إعداد**: لا حاجة لخادم قاعدة بيانات منفصل
2. **الامتثال لـ ACID**: يضمن سلامة الفهرس
3. **استعلامات LIKE فعالة**: مطابقة نمط مدمجة للبحث الجزئي
4. **متعدد المنصات**: يعمل على Windows، Linux، macOS
5. **مدمج**: الفهرس يسافر مع التطبيق

### لماذا العمليات القائمة على المجموعات؟

1. **البساطة**: تمثيل طبيعي لـ "الآيات التي تحتوي على كلمة X"
2. **الكفاءة**: عمليات المجموعات المدمجة في Python محسّنة للغاية
3. **المرونة**: سهل للجمع (AND/OR) مصطلحات بحث متعددة
4. **الذاكرة**: تمثيل مضغوط للبيانات المتناثرة

## البناء والتثبيت

### توليد فهرس البحث

```bash
python3 gen-index.py
```

هذا ينشئ `othman-data/ix.db` من خلال فهرسة جميع النص القرآني.

### تثبيت التطبيق

```bash
pip3 install --upgrade git+https://github.com/ojuba-org/othman.git --user
othman-browser
```

### البناء من المصدر

```bash
# Using Make
make
sudo make install

# Using Meson
meson build
ninja -C build
sudo ninja -C build install
```

## الترخيص

صدر تحت **رخصة الوقف العامة** - رخصة كوبيليفت مصممة للبرمجيات الإسلامية التي تضمن بقاء العمل متاحاً مجاناً كشكل من أشكال الصدقة الجارية.

